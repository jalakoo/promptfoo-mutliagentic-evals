# yaml-language-server: $schema=https://promptfoo.dev/config-schema.json

# Learn more about building a configuration: https://promptfoo.dev/docs/configuration/guide

description: "LLM + LLM Agentic Frameworks + MCP Evals"

prompts:
  - "{{question}}"

providers:
  # -----------------------------
  # Testing CrewAI
  # -----------------------------
    - id: "file://crewai_manager.py"
      label: "crewai"
  # - id: "file://crewai_manager.py"
  #   label: "crewai-ollama/gpt-oss:20b"
  #   config: {
  #     "model_name" : "ollama/gpt-oss:20b"
  #   }
  # - id: "file://crewai_manager.py"
  #   label: "crewai-ollama/qwen3"
  #   config: {
  #     "model_name" : "ollama/qwen3"
  #   }
  # - id: "file://crewai_manager.py"
  #   label: "crewai-ollama/llama3.2"
  #   config: {
  #     "model_name" : "ollama/llama3.2"
  #   }
  # - id: "file://crewai_manager.py"
  #   label: "crewai-ollama/lfm2-1.2b"
  #   config: {
  #     "model_name" : "ollama/lfm2-1.2b"
  #   }
  # - id: "file://crewai_manager.py"
  #   label: "crewai-sambanova/llama-3.1-8b-instruct"
  #   config: {
  #     "model_name" : "sambanova/llama-3.1-8b-instruct"
  #   }
  # - id: "file://crewai_manager.py"
  #   label: "crewai-sambanova/Llama-4-Maverick-17B-128E-Instruct"
  #   config: {
  #     "model_name" : "sambanova/Llama-4-Maverick-17B-128E-Instruct"
  #   }
  # - id: "file://crewai_manager.py"
  #   label: "crewai-openai/o3-mini"
  #   config: {
  #     "model_name" : "openai/o3-mini"
  #   }
  # - id: "file://crewai_manager.py"
  #   label: "crewai-openai/gpt-5"
  #   config: {
  #     "model_name" : "openai/gpt-5"
  #   }
  # - id: "file://crewai_manager.py"
  #   label: "crewai-openai/gpt-4.1"
  #   config: {
  #     "model_name" : "openai/gpt-4.1"
  #   }
  # - id: "file://crewai_manager.py"
  #   label: "crewai-anthropic/claude-3-haiku-20240307"
  #   config: {
  #     "model_name" : "anthropic/claude-3-haiku-20240307"
  #   }
  # - id: "file://crewai_manager.py"
  #   label: "crewai-anthropic/claude-opus-4-1-20250805"
  #   config: {
  #     "model_name" : "anthropic/claude-opus-4-1-20250805"
  #   }

  # -----------------------------
  # Testing LangGraph
  # -----------------------------
    - id: "file://langgraph_manager.py"
      label: "langgraph"
  # - id: "file://langgraph_manager.py"
  #   label: "langgraph-ollama/gpt-oss:20b"
  #   config: {
  #     "model_name" : "ollama/gpt-oss:20b"
  #   }
  # - id: "file://langgraph_manager.py"
  #   label: "langgraph-ollama/qwen3"
  #   config: {
  #     "model_name" : "ollama/qwen3"
  #   }
  # - id: "file://langgraph_manager.py"
  #   label: "langgraph-ollama/llama3.2"
  #   config: {
  #     "model_name" : "ollama/llama3.2"
  #   }
  # - id: "file://langgraph_manager.py"
  #   label: "langgraph-ollama/lfm2-1.2b"
  #   config: {
  #     "model_name" : "ollama/lfm2-1.2b"
  #   }
  # - id: "file://langgraph_manager.py"
  #   label: "langgraph-sambanova/llama-3.1-8b-instruct"
  #   config: {
  #     "model_name" : "sambanova/llama-3.1-8b-instruct"
  #   }
  # - id: "file://langgraph_manager.py"
  #   label: "langgraph-sambanova/Llama-4-Maverick-17B-128E-Instruct"
  #   config: {
  #     "model_name" : "sambanova/Llama-4-Maverick-17B-128E-Instruct"
  #   }
  # - id: "file://langgraph_manager.py"
  #   label: "langgraph-openai/o3-mini"
  #   config: {
  #     "model_name" : "openai/o3-mini"
  #   }
  # - id: "file://langgraph_manager.py"
  #   label: "langgraph-openai/gpt-5"
  #   config: {
  #     "model_name" : "openai/gpt-5"
  #   }
  # - id: "file://langgraph_manager.py"
  #   label: "langgraph-openai/gpt-4.1"
  #   config: {
  #     "model_name" : "openai/gpt-4.1"
  #   }
  # - id: "file://langgraph_manager.py"
  #   label: "langgraph-anthropic/claude-3-haiku-20240307"
  #   config: {
  #     "model_name" : "anthropic/claude-3-haiku-20240307"
  #   }
  # - id: "file://langgraph_manager.py"
  #   label: "langgraph-anthropic/claude-opus-4-1-20250805"
  #   config: {
  #     "model_name" : "anthropic/claude-opus-4-1-20250805"
  #   }

  # -----------------------------
  # Testing LllamaIndex
  # -----------------------------
    - id: "file://llamaindex_manager.py"
      label: "llamaindex"

  # - id: "file://llamaindex_manager.py"
  #   label: "llamaindex-ollama/gpt-oss:20b"
  #   config: {
  #     "model_name" : "ollama/gpt-oss:20b"
  #   }
  # - id: "file://llamaindex_manager.py"
  #   label: "llamaindex-ollama/qwen3"
  #   config: {
  #     "model_name" : "ollama/qwen3"
  #   }
  # - id: "file://llamaindex_manager.py"
  #   label: "llamaindex-ollama/llama3.2"
  #   config: {
  #     "model_name" : "ollama/llama3.2"
  #   }
  # - id: "file://llamaindex_manager.py"
  #   label: "llamaindex-ollama/lfm2-1.2b"
  #   config: {
  #     "model_name" : "ollama/lfm2-1.2b"
  #   }
  # - id: "file://llamaindex_manager.py"
  #   label: "llamaindex-sambanova/Llama-4-Maverick-17B-128E-Instruct"
  #   config: {
  #     "model_name" : "sambanova/Llama-4-Maverick-17B-128E-Instruct"
  #   }
  # - id: "file://llamaindex_manager.py"
  #   label: "llamaindex-sambanova/Llama-4-Maverick-17B-128E-Instruct"
  #   config: {
  #     "model_name" : "sambanova/Llama-4-Maverick-17B-128E-Instruct"
  #   }
  # - id: "file://llamaindex_manager.py"
  #   label: "llamaindex-openai/o3-mini"
  #   config: {
  #     "model_name" : "openai/o3-mini"
  #   }
  # - id: "file://llamaindex_manager.py"
  #   label: "llamaindex-openai/gpt-5"
  #   config: {
  #     "model_name" : "openai/gpt-5"
  #   }
  # - id: "file://llamaindex_manager.py"
  #   label: "llamaindex-openai/gpt-4.1"
  #   config: {
  #     "model_name" : "openai/gpt-4.1"
  #   }
  # - id: "file://llamaindex_manager.py"
  #   label: "llamaindex-anthropic/claude-3-haiku-20240307"
  #   config: {
  #     "model_name" : "anthropic/claude-3-haiku-20240307"
  #   }
  # - id: "file://llamaindex_manager.py"
  #   label: "llamaindex-anthropic/claude-opus-4-1-20250805"
  #   config: {
  #     "model_name" : "anthropic/claude-opus-4-1-20250805"
  #   }

# tracing:
#   enabled: true # Enable/disable tracing
#   otlp:
#     http:
#       enabled: true # Required to start the OTLP receiver
      # port: 4318   # Optional - defaults to 4318 (standard OTLP HTTP port)
      # host: '0.0.0.0'  # Optional - defaults to '0.0.0.0'

tests:
  # These tests intended for running against the Neo4j Northwinds Dataset
  # See the included sample.env file for read-only credentials to access
  # a hosted instance of this dataset

  # For using multiple variables, see https://www.promptfoo.dev/docs/configuration/guide/#multiple-variables-in-a-single-test-case

  # Simple count queries
  - vars:
      question: "How many nodes are in the database?"
      model_name:
        - "ollama/llama3.2"
        # - "ollama/gpt-oss:20b"
        # - "ollama/qwen3"
        # - "ollama/lfm2-1.2b"
        # - "sambanova/llama-3.1-8b-instruct"
        # - "sambanova/Llama-4-Maverick-17B-128E-Instruct"
        # - "openai/o3-mini"
        # - "openai/gpt-5"
        # - "openai/gpt-4.1"
        # - "anthropic/claude-3-haiku-20240307"
        # - "anthropic/claude-opus-4-1-20250805"
    assert:
      - type: contains-any
        value: 
          - "1035"
          - "1,035"

  # - vars:
  #     question: "How many customers are there?"
  #   assert:
  #     - type: icontains
  #       value: "91"

  # 1 hop queries
  # - vars:
  #     question: "How many products does Tokyo Traders supply?"
  #   assert:
  #     - type: icontains
  #       value: "3"

  # - vars:
  #     question: "How many orders for Ikura were made?"
  #   assert:
  #     - type: icontains
  #       value: "33"


  # 2 hop queries

  # Query to confirm
  # MATCH (c:Customer)-[:PURCHASED]->(o:Order)-[:ORDERS]->(p:Product)-[:PART_OF]->(cat:Category)
  # WHERE cat.categoryName = 'Produce'
  # RETURN count(DISTINCT c) as customerCount
  # - vars:
  #     question: "How many customers purchased Produce products?"
  #   assert:
  #     - type: icontains
  #       value: "63"

  # Query to confirm
  # MATCH (c:Customer)-[:PURCHASED]->(o:Order)-[:ORDERS]->(p:Product)
  # WITH max(p.unitPrice) as maxPrice
  # MATCH (c:Customer)-[:PURCHASED]->(o:Order)-[:ORDERS]->(p:Product)
  # WHERE p.unitPrice = maxPrice
  # RETURN c.companyName
  # ORDER BY c.companyName ASC
  # LIMIT 1
  # - vars:
  #     question: "Which customer purchased the most expensive product (first alphabetically if more than one)?"
  #   assert:
  #     - type: contains-any
  #       value: 
  #         - "Berglunds"
  #         - "snabbk√∂p"



  # Multi-hop aggregration queries

  # Query to confirm
  # MATCH (c:Customer)-[:PURCHASED]-(o:Order)-[or:ORDERS]-(p:Product)
  # WHERE p.productName = "Longlife Tofu"
  # WITH c, o,  sum(or.quantity) as total_quantity
  # RETURN c, o, total_quantity
  # ORDER BY total_quantity DESC
  # - vars:
  #     question: "Which customer orders the largest number of Longlife Tofu?"
  #   assert:
  #     - type: icontains
  #       value: "Ernst Handel"

  # Query to confirm
  # MATCH (o:Order)-[or:ORDERS]-(p:Product)
  # WHERE p.productName = "Mishi Kobe Niku"
  # WITH p, sum(or.quantity) AS total_quantity, sum(or.quantity * p.unitPrice) as total_sales
  # RETURN total_quantity AS units_sold, total_sales
  # ORDER BY total_sales DESC

  # - vars:
  #     question: "What is the totals sales value of all Mishi Kobe Niku orders?"
  #   assert:
  #     - type: contains-any
  #       value: 
  #         - "9215"
  #         - "9,215"