# yaml-language-server: $schema=https://promptfoo.dev/config-schema.json

# Learn more about building a configuration: https://promptfoo.dev/docs/configuration/guide

description: "All Frameworks + Anthropic Models + 1&2&mulit hop questions"

prompts:
  - "{{question}}"

providers:
  # -----------------------------
  # Testing CrewAI
  # -----------------------------
   # Example using test vars for model name definitions
    - id: "file://crewai_manager.py"
      label: "crewai"

  # Example using provider config for model name definitions
  # - id: "file://crewai_manager.py"
  #   label: "crewai-ollama/gpt-oss:20b"
  #   config: {
  #     "model_name" : "ollama/gpt-oss:20b"
  #   }


  # -----------------------------
  # Testing LangGraph
  # -----------------------------
    - id: "file://langgraph_manager.py"
      label: "langgraph"
  # - id: "file://langgraph_manager.py"
  #   label: "langgraph-ollama/gpt-oss:20b"
  #   config: {
  #     "model_name" : "ollama/gpt-oss:20b"
  #   }
 

  # -----------------------------
  # Testing LllamaIndex
  # -----------------------------
    - id: "file://llamaindex_manager.py"
      label: "llamaindex"

  # - id: "file://llamaindex_manager.py"
  #   label: "llamaindex-ollama/gpt-oss:20b"
  #   config: {
  #     "model_name" : "ollama/gpt-oss:20b"
  #   }


# tracing:
#   enabled: true # Enable/disable tracing
#   otlp:
#     http:
#       enabled: true # Required to start the OTLP receiver
      # port: 4318   # Optional - defaults to 4318 (standard OTLP HTTP port)
      # host: '0.0.0.0'  # Optional - defaults to '0.0.0.0'

tests:
  # These tests intended for running against the Neo4j Northwinds Dataset
  # See the included sample.env file for read-only credentials to access
  # a hosted instance of this dataset

  # For using multiple variables, see https://www.promptfoo.dev/docs/configuration/guide/#multiple-variables-in-a-single-test-case

  # This can be answered with a schema query
  # Simple count queries
  # - vars:
  #     question: "How many nodes are in the database?"
  #     model_name:
  #       - "ollama/llama3.2"
  #       # - "ollama/gpt-oss:20b"
  #       # - "ollama/qwen3"
  #       # - "ollama/lfm2-1.2b"
  #       - "sambanova/Meta-Llama-3.1-8B-Instruct"
  #       # - "sambanova/Llama-4-Maverick-17B-128E-Instruct"
  #       - "openai/o3-mini"
  #       # - "openai/gpt-5"
  #       # - "openai/gpt-4.1"
  #       - "anthropic/claude-3-haiku-20240307"
  #       # - "anthropic/claude-opus-4-1-20250805"
  #   assert:
  #     - type: contains-any
  #       value: 
  #         - "1035"
  #         - "1,035"

  # This can be answered with a schema query
  # - vars:
  #     question: "How many customers are there?"
  #     model_name:
  #       - "ollama/llama3.2"
  #       # - "ollama/gpt-oss:20b"
  #       # - "ollama/qwen3"
  #       # - "ollama/lfm2-1.2b"
  #       # - "sambanova/Meta-Llama-3.1-8B-Instruct"
  #       # - "sambanova/Llama-4-Maverick-17B-128E-Instruct"
  #       # - "openai/o3-mini"
  #       # - "openai/gpt-5"
  #       # - "openai/gpt-4.1"
  #       # - "anthropic/claude-3-haiku-20240307"
  #       # - "anthropic/claude-opus-4-1-20250805"
  #       # - "non-existent-model"
  #   assert:
  #     - type: icontains
  #       value: "91"

  # 1 hop queries

  # Query to confirm
  # MATCH (s:Supplier {companyName: 'Tokyo Traders'})-[:SUPPLIES]->(p:Product)
  # RETURN count(p) as productCount
  # - vars:
  #     question: "How many products does Tokyo Traders supply?"
  #     model_name:
  #       # - "ollama/llama3.2"
  #       # - "ollama/gpt-oss:20b"
  #       # - "ollama/qwen3"
  #       # - "ollama/lfm2-1.2b"
  #       # Groq function calling models
  #       # - "groq/moonshotai/kimi-k2-instruct-0905"
  #       # - "groq/openai/gpt-oss-20b"
  #       - "groq/openai/gpt-oss-120b"
  #       # - "groq/qwen/qwen3-32b"
  #       - "groq/meta-llama/llama-4-scout-17b-16e-instruct"
  #       # - "groq/meta-llama/llama-4-maverick-17b-128e-instruct"
  #       # - "groq/llama-3.3-70b-versatile"
  #       # - "groq/llama-3.1-8b-instant"
  #       # - "sambanova/Meta-Llama-3.1-8B-Instruct"
  #       # - "sambanova/Llama-4-Maverick-17B-128E-Instruct"
  #       # - "openai/o3-mini"
  #       # - "openai/gpt-5"
  #       # - "openai/gpt-4.1"
  #       # - "anthropic/claude-3-haiku-20240307"
  #       # - "anthropic/claude-opus-4-1-20250805"
  #       # - "cerebras/qwen-3-235b-a22b-instruct-2507"
  #       # - "non-existent-model"
  #   assert:
  #     - type: icontains
  #       value: "3"

  # Query to confirm
  # MATCH (o:Order)-[:ORDERS]->(p:Product)
  # WHERE toLower(p.productName) = 'ikura'
  # RETURN count(o) as orderCount
  - vars:
      question: "How many orders for Ikura were made?"
      model_name:
        # - "ollama/llama3.2"
        # - "ollama/gpt-oss:20b"
        # - "ollama/qwen3"
        # - "ollama/lfm2-1.2b"
        # - "sambanova/Meta-Llama-3.1-8B-Instruct"
        # - "sambanova/Llama-4-Maverick-17B-128E-Instruct"
        # - "openai/o3-mini"
        # - "openai/gpt-5"
        # - "openai/gpt-4.1"
        # Anthropic models
        - "anthropic/claude-sonnet-4-5-20250929"
        - "anthropic/claude-haiku-4-5-20251001"
        - "anthropic/claude-opus-4-1-20250805"
        # Groq function calling models
        # - "groq/moonshotai/kimi-k2-instruct-0905"
        # - "groq/openai/gpt-oss-20b"
        # - "groq/openai/gpt-oss-120b"
        # - "groq/qwen/qwen3-32b"
        # - "groq/meta-llama/llama-4-scout-17b-16e-instruct"
        # - "groq/meta-llama/llama-4-maverick-17b-128e-instruct"
        # - "groq/llama-3.3-70b-versatile"
        # - "groq/llama-3.1-8b-instant"
        # - "cerebras/qwen-3-235b-a22b-instruct-2507"
        # - "non-existent-model"
    assert:
      - type: icontains
        value: "33"


  # 2 hop queries

  # Query to confirm
  # MATCH (c:Customer)-[:PURCHASED]->(o:Order)-[:ORDERS]->(p:Product)-[:PART_OF]->(cat:Category)
  # WHERE cat.categoryName = 'Produce'
  # RETURN count(DISTINCT c) as customerCount
  - vars:
      question: "How many customers purchased Produce products?"
      model_name:
        # - "ollama/llama3.2"
        # - "ollama/gpt-oss:20b"
        # - "ollama/qwen3"
        # - "ollama/lfm2-1.2b"
        # - "sambanova/Meta-Llama-3.1-8B-Instruct"
        # - "sambanova/Llama-4-Maverick-17B-128E-Instruct"
        # - "openai/o3-mini"
        # - "openai/gpt-5"
        # - "openai/gpt-4.1"
        # Anthropic models
        - "anthropic/claude-sonnet-4-5-20250929"
        - "anthropic/claude-haiku-4-5-20251001"
        - "anthropic/claude-opus-4-1-20250805"
        # Groq function calling models
        # - "groq/moonshotai/kimi-k2-instruct-0905"
        # - "groq/openai/gpt-oss-20b"
        # - "groq/openai/gpt-oss-120b"
        # - "groq/qwen/qwen3-32b"
        # - "groq/meta-llama/llama-4-scout-17b-16e-instruct"
        # - "groq/meta-llama/llama-4-maverick-17b-128e-instruct"
        # - "groq/llama-3.3-70b-versatile"
        # - "groq/llama-3.1-8b-instant"
        # - "cerebras/qwen-3-235b-a22b-instruct-2507"
        # - "non-existent-model"
    assert:
      - type: icontains
        value: "63"

  # Query to confirm
  # MATCH (c:Customer)-[:PURCHASED]->(o:Order)-[:ORDERS]->(p:Product)
  # WITH max(p.unitPrice) as maxPrice
  # MATCH (c:Customer)-[:PURCHASED]->(o:Order)-[:ORDERS]->(p:Product)
  # WHERE p.unitPrice = maxPrice
  # RETURN c.companyName
  # ORDER BY c.companyName ASC
  # LIMIT 1
  # - vars:
  #     question: "Which customer purchased the most expensive product (first alphabetically if more than one)?"
  #   assert:
  #     - type: contains-any
  #       value: 
  #         - "Berglunds"
  #         - "snabbk√∂p"



  # Multi-hop aggregration queries

  # Query to confirm
  # MATCH (c:Customer)-[:PURCHASED]-(o:Order)-[or:ORDERS]-(p:Product)
  # WHERE p.productName = "Longlife Tofu"
  # WITH c, o,  sum(or.quantity) as total_quantity
  # RETURN c, o, total_quantity
  # ORDER BY total_quantity DESC
  - vars:
      question: "Which customer orders the largest number of Longlife Tofu?"
      model_name:
        # - "ollama/llama3.2"
        # - "ollama/gpt-oss:20b"
        # - "ollama/qwen3"
        # - "ollama/lfm2-1.2b"
        # - "sambanova/Meta-Llama-3.1-8B-Instruct"
        # - "sambanova/Llama-4-Maverick-17B-128E-Instruct"
        # - "openai/o3-mini"
        # - "openai/gpt-5"
        # - "openai/gpt-4.1"
        # Anthropic models
        - "anthropic/claude-sonnet-4-5-20250929"
        - "anthropic/claude-haiku-4-5-20251001"
        - "anthropic/claude-opus-4-1-20250805"
        # Groq function calling models
        # - "groq/moonshotai/kimi-k2-instruct-0905"
        # - "groq/openai/gpt-oss-20b"
        # - "groq/openai/gpt-oss-120b"
        # - "groq/qwen/qwen3-32b"
        # - "groq/meta-llama/llama-4-scout-17b-16e-instruct"
        # - "groq/meta-llama/llama-4-maverick-17b-128e-instruct"
        # - "groq/llama-3.3-70b-versatile"
        # - "groq/llama-3.1-8b-instant"
        # - "cerebras/qwen-3-235b-a22b-instruct-2507"
        # - "non-existent-model"
    assert:
      - type: icontains
        value: "Ernst Handel"

  # Query to confirm
  # MATCH (o:Order)-[or:ORDERS]-(p:Product)
  # WHERE p.productName = "Mishi Kobe Niku"
  # WITH p, sum(or.quantity) AS total_quantity, sum(or.quantity * p.unitPrice) as total_sales
  # RETURN total_quantity AS units_sold, total_sales
  # ORDER BY total_sales DESC

  # - vars:
  #     question: "What is the totals sales value of all Mishi Kobe Niku orders?"
  #   assert:
  #     - type: contains-any
  #       value: 
  #         - "9215"
  #         - "9,215"